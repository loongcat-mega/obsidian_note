
> [! error] 3个文件尚未迁移
> exec
> load_data
> base_cfgs
> - `Dataset`这个类的对应关系没找到
> 	- DataLoader与DataParallel
> - 梯度这块`clip_grad_norm_`
> 	- PyTorch中梯度是Tensor的属性，可以通过设置`requires_grad=True`使Tensor带有梯度。由于框架机制的不同，在MindSpore中，梯度和权重是互相独立的Tensor。因此在梯度裁剪时，MindSpore需要先获取梯度Tensor再进行裁剪。
> 	- PyTorch中能实现原地梯度裁剪，Mindspore中梯度先提取出来，再裁剪



### load_data

```python
Dataset类正在对应Mindspore中对应类
import torch.utils.data as Data
```
![image.png](https://yaaame-1317851743.cos.ap-beijing.myqcloud.com/20240119144314.png)


torch中Dataset类：
![image.png](https://yaaame-1317851743.cos.ap-beijing.myqcloud.com/20240119144608.png)




### base_cfgs

#### proc

Mindspore没有找到对应的api
```python
torch.set_num_threads(2)
# ------------ Seed setup
# fix pytorch seed
torch.manual_seed(self.SEED)
if self.N_GPU < 2:
torch.cuda.manual_seed(self.SEED)
else:
torch.cuda.manual_seed_all(self.SEED)
torch.backends.cudnn.deterministic = True
```


### exec

#### train方法


Net网络有cuda方法和train方法吗？
```python
net = Net(
    self.__C,
    pretrained_emb,
    token_size,
    ans_size
)
net.cuda()
net.train()

```
`DataParallel`这个方法没对应明白[mindspore.set_auto_parallel_context](https://www.mindspore.cn/docs/zh-CN/r2.2/api_python/mindspore/mindspore.set_auto_parallel_context.html#Popover19-toggle:~:text=mindspore.set_auto_parallel_context)

[比较与torch.utils.data.DataLoader的差异](https://www.mindspore.cn/docs/zh-CN/r2.2/note/api_mapping/pytorch_diff/DataLoader.html#Popover19-toggle:~:text=%E6%AF%94%E8%BE%83%E4%B8%8Etorch.utils.data.DataLoader%E7%9A%84%E5%B7%AE%E5%BC%82)

```python
 nn.utils.clip_grad_norm_(
                        net.parameters(),
                        self.__C.GRAD_NORM_CLIP
                    )
```
[比较与torch.nn.utils.clip_grad_norm_的差异](https://www.mindspore.cn/docs/zh-CN/r2.2/note/api_mapping/pytorch_diff/clip_by_norm.html#Popover19-toggle:~:text=%E6%AF%94%E8%BE%83%E4%B8%8Etorch.nn.utils.clip_grad_norm_%E7%9A%84%E5%B7%AE%E5%BC%82)

