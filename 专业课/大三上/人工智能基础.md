
人工智能起源于1956年的达特思茅会议上，麦卡锡首次提出Artificial Intelligence

人工智能的研究方法：
- 符号主义
    - 人工智能的基本单元是符号
    - 自上而下和符号主义
    - 缺点：
        - 难以模拟形象思维，且有信息丢失的情况
- 连接主义
    - 以网络连接为主
    - 自下而上和连接主义
    - 缺点：
        - 不适合解决逻辑思维
- 行为主义
    - 进化主义或控制论学派 基于控制论



## 知识

知识就是描述世界的一组约定
知识表示方法：
- 谓词逻辑
    - 谓词逻辑表示法是知识表示的基础
    - 命题逻辑
        - 命题：具有真假意义的陈述句
        - 命题逻辑：命题常量、命题变元、谓词逻辑
    - 谓词逻辑
        - 函数符号与谓词符号
        - ![image.png](https://yaaame-1317851743.cos.ap-beijing.myqcloud.com/20240103182521.png)
            - 一阶谓词表示法优点：
                - 严密性 自然性 通用性
            - 缺点：
                - 效率低 灵活性差 组合爆炸
- 状态空间
- 产生式规则
    - 产生式表示法是目前应用最为广泛的知识表示方法
    - 适合表示 事实性知识和规则性知识 具有因果关系的知识
    - 产生式系统组成：
        - 控制系统
        - 规则库-->核心
        - 综合数据库
    - 产生式系统推理方式：
        - 正向推理
            - 数据驱动方式 自底向上
        - 反向推理
            - 目标驱动方式 自顶向下
        - 双向推理
- 语义网络
    - 有向图，结点和弧必须带有标注，与逻辑表示法对应
    - 由最基本的语义单元组成：(结点1，弧，结点2)
    - 推理过程：
        - 继承
        - 匹配
- 框架
- 概念从属
- 脚本
- Petri网

## 推理

### 演绎推理
从已知的一般性知识出发，去推导出蕴含在这些已知的知识中的适合某种个别情况的结论
是一种**由一般到个别**的推理方法，其核心是**三段论**

不能增殖新知识


### 归纳推理

按照某种策略从已知事实出发去推出结论的过程
是一种**从个别到一般**的推理方法

能增殖新知识

例如，一位计算机维修员，从书本知识，到通过大量实例积累经验是一种归纳推理方式。
运用这些一般性知识去维修计算机的过程则是演绎推理。

### 推理的逻辑基础

### 置换与合一

置换是在一个谓词公式中用置换项去替换变量
用项去置换变元
- 项：a,g(a),f(x)
- 变元：x,y
置换是用希腊字母θ、σ、 α、 λ等来表示的

置换乘法：
![image.png](https://yaaame-1317851743.cos.ap-beijing.myqcloud.com/20240104210647.png)


合一理解为寻找项对变量的置换，使两个谓词公式一致
$$
设有公式集F=\{F_1,F_2,...,F_n\},若存在一个置换\theta ,可使F_{1}\theta =F_2\theta =F_n\theta \quad则称\theta为F的一个合一
$$
![image.png](https://yaaame-1317851743.cos.ap-beijing.myqcloud.com/20240104211132.png)


### 自然演绎推理

避免两类错误：
- 肯定后件的错误:当P->Q为真时，希望通过肯定后件Q为真来推出前件P为真，这是不允许的
- 否定前件的错误

容易产生知识爆炸

### 归结演绎推理

基于鲁滨逊归结原理，也叫消解原理：反证法，把关于永真性的证明转换为不可满足性问题

#### 子句集及其化简

原子谓词公式及其否定统称为文字
任何文字的析取式称为字句
空子句NIL

子句集化简：
- 消去连接词
- 减少否定符号的辖域
- 对变元标准化（在量词辖域内做名字替换）
- 化为前束范式：所有量词移到公式左边
- 消去存在量词：用Skolem函数来替换
- 化为Skolem标准型：子句合取
- 消去全称量词
- 消去合取词
- 更改变量名称


## 搜索策略

搜索问题包括：
- 状态空间S
- 初始状态s_0
- 动作集合
- 转移模型
- 目标测试

### 盲目搜索


#### DFS

策略：首先扩展最深的结点
实现：Open栈
完备性：不完备
最优解：不

#### BFS
策略：优先扩展最浅的结点
实现：Open队列
完备性：是
最优解：是


#### UFS
策略：扩展最小的g(n)
实现：Open优先队列
完备性：是
最优解：是


### 启发式搜索

状态空间搜索：列出问题的状态空间

$f(n)=g(n)+h(n)$

八数码问题

A*  算法组合UCS和贪心


### 问题归约和 与或图启发式搜索

问题归约是求解问题常用的策略：把复杂问题变为若干需要同时处理的简单子问题再加以分别求解（子问题为本原问题）

与或图：与表示问题分解为子问题，或表示问题可以有多种分解方式

k-连接与解图（所有k-连接都指向终结点）




## 机器学习入门

### 数据处理

#### 预处理
- 数据清洗
    - 完备性
    - 合法性
    - 一致性
    - 唯一性
    - 权威性
- 数据采样
    - 过采样
    - 欠采样
- 数据集拆分
    - 训练集
    - 验证集
    - 测试集

#### 特征工程

- 特征选择：
    - 过滤法
    - 包裹法
    - 嵌入法
- 特征降维
    - 主成成份分析
    - LDA
- 特征编码
    - One-hot编码
    - 语义编码
- 规范化
    - 标准化
    - 区间缩放
    - 归一化


### 学习方法

归纳学习
强化学习:只给出评价信息而非正确答案
多任务学习

## 深度学习

人工智能是模拟、延伸和扩展人的智能的科学

全连接层参数巨大，不能充分应用数据的某些特性
卷积神经网络：
- 局部连接

循环神经网络：
- 时序，处理序列数据


激活函数：
- 增强网络的表达能力
- 对输入数据做非线性变换

softmax函数
- 预测的概率为非负数
- 各种预测结果的概率和为1

损失函数
- 计算模型预测值与真实值之间的误差
- 确定参数使得总损失最小

交叉熵损失函数
$$
H(y_i,\hat y_i)=-y_i*log\hat y_i
$$


### 卷积神经网络

图像的哪个区块:特征检测因子
把图像区块描述为向量:特征描述因子

卷积
- 平移不变

池化
- 下采样被检测物体不变模式
    - 降维，去除冗余信息
    - 实现非线性，防止过拟合


卷积神经网络结构上三大特性：减少网络参数，加快训练速度
- 局部连接
- 权重共享
- 下采样




